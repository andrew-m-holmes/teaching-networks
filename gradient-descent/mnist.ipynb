{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1ac3d0-b01d-4597-ba97-004d58b85316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28583600-2e6f-4759-9e9f-c5b087ef2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_dataset(\"mnist\")\n",
    "train, test = mnist.get(\"train\"), mnist.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6693dc6e-5cce-49af-8072-89ddd7c983f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_format(type=\"numpy\", columns=[\"image\", \"label\"])\n",
    "test.set_format(type=\"numpy\", columns=[\"image\", \"label\"])\n",
    "num_train_samples = 10000\n",
    "num_test_samples = 1000\n",
    "\n",
    "train_indices = np.random.choice(num_train_samples, num_train_samples, replace=False)\n",
    "test_indices = np.random.choice(num_test_samples, num_test_samples, replace=False)\n",
    "train = train.rename_column(\"image\", \"input\").select(train_indices)\n",
    "test = test.rename_column(\"image\", \"input\").select(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe26ee2-d4aa-4a73-965f-7e61a2cdc8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5903fdc3b3374b9896cd8cde45c75b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdb311237a24357a5968503c04fc375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
     ]
    }
   ],
   "source": [
    "def reshape(example):\n",
    "    example[\"input\"] = np.reshape(example[\"input\"], -1)\n",
    "    return example\n",
    "\n",
    "train = train.map(reshape, num_proc=2)\n",
    "test = test.map(reshape, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dfbf84-963a-4231-acc6-b24ed0e5df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.from_numpy(train[\"input\"]).float().squeeze()\n",
    "test_inputs = torch.from_numpy(test[\"input\"]).float().squeeze()\n",
    "train_labels = torch.from_numpy(train[\"label\"]).long()\n",
    "test_labels = torch.from_numpy(test[\"label\"]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fd4ac4-b049-492c-884e-afc8064dd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_inputs, train_labels)\n",
    "test_dataset = data.TensorDataset(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4dd86ed-fb34-4c30-bc3f-8912dab76e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(28 * 28, 512)\n",
    "        self.norm_1 = nn.LayerNorm(512)\n",
    "        self.drop_1 = nn.Dropout(p=0.5)\n",
    "        self.linear_2 = nn.Linear(512, 512)\n",
    "        self.norm_2 = nn.LayerNorm(512)\n",
    "        self.drop_2 = nn.Dropout(p=0.25)\n",
    "        self.linear_3 = nn.Linear(512, 256)\n",
    "        self.norm_3 = nn.LayerNorm(256)\n",
    "        self.linear_4 = nn.Linear(256, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_1(f.relu(self.norm_1(self.linear_1(x))))\n",
    "        x = self.drop_2(f.relu(self.norm_2(self.linear_2(x))))\n",
    "        x = f.relu(self.norm_3(self.linear_3(x)))\n",
    "        out = self.linear_4(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd2d913-8c03-4247-8aec-23d992e7d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size):\n",
    "    return data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)\n",
    "\n",
    "def test(model, dataloader,  device=None, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Testing has started\")\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "            \n",
    "        test_loss /= len(dataloader)\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"Testing complete, loss: {test_loss:.3f}\")\n",
    "        \n",
    "    return test_loss\n",
    "\n",
    "def train(model, optimizer, train_dataloader, test_dataloader, epochs=10, device=None, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Training has started\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        num_samples = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                correct = torch.sum(torch.argmax(outputs, dim=-1) == labels)\n",
    "                accuracy += correct.item()\n",
    "                num_samples += len(labels)\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        accuracy /= num_samples\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1} complete, train loss: {train_loss:.3f}, test loss: {test_loss:.3f}, accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training is complete\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dbdc3-2cf6-4187-8c0a-9dd809380f4e",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d552508-7ac6-41ea-9f33-0e51bb672f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dataloader = create_dataloader(train_dataset, batch_size=len(train_dataset))\n",
    "test_dataloader = create_dataloader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6826022-8e5c-4749-9b05-88a1c5df5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 801034\n"
     ]
    }
   ],
   "source": [
    "print(f\"parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce172db-fe01-4b15-90b0-5e8438931975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "Epoch 1 complete, train loss: 2.369, test loss: 2.121, accuracy: 27.00\n",
      "Epoch 2 complete, train loss: 2.205, test loss: 1.864, accuracy: 55.60\n",
      "Epoch 3 complete, train loss: 2.060, test loss: 1.676, accuracy: 53.40\n",
      "Epoch 4 complete, train loss: 1.927, test loss: 1.463, accuracy: 63.70\n",
      "Epoch 5 complete, train loss: 1.787, test loss: 1.353, accuracy: 62.10\n",
      "Epoch 6 complete, train loss: 1.657, test loss: 1.213, accuracy: 66.00\n",
      "Epoch 7 complete, train loss: 1.564, test loss: 1.237, accuracy: 58.50\n",
      "Epoch 8 complete, train loss: 1.488, test loss: 1.176, accuracy: 63.00\n",
      "Epoch 9 complete, train loss: 1.478, test loss: 1.160, accuracy: 61.80\n",
      "Epoch 10 complete, train loss: 1.350, test loss: 1.048, accuracy: 66.80\n",
      "Epoch 11 complete, train loss: 1.307, test loss: 1.066, accuracy: 66.00\n",
      "Epoch 12 complete, train loss: 1.227, test loss: 0.949, accuracy: 70.20\n",
      "Epoch 13 complete, train loss: 1.164, test loss: 1.026, accuracy: 63.70\n",
      "Epoch 14 complete, train loss: 1.159, test loss: 0.902, accuracy: 71.50\n",
      "Epoch 15 complete, train loss: 1.083, test loss: 0.912, accuracy: 68.80\n",
      "Epoch 16 complete, train loss: 1.033, test loss: 0.911, accuracy: 69.90\n",
      "Epoch 17 complete, train loss: 1.039, test loss: 1.066, accuracy: 62.60\n",
      "Epoch 18 complete, train loss: 1.099, test loss: 0.865, accuracy: 70.90\n",
      "Epoch 19 complete, train loss: 0.992, test loss: 0.730, accuracy: 75.10\n",
      "Epoch 20 complete, train loss: 0.823, test loss: 0.655, accuracy: 78.00\n",
      "Epoch 21 complete, train loss: 0.772, test loss: 0.658, accuracy: 77.20\n",
      "Epoch 22 complete, train loss: 0.748, test loss: 0.639, accuracy: 79.20\n",
      "Epoch 23 complete, train loss: 0.738, test loss: 0.669, accuracy: 75.60\n",
      "Epoch 24 complete, train loss: 0.742, test loss: 0.645, accuracy: 78.90\n",
      "Epoch 25 complete, train loss: 0.733, test loss: 0.652, accuracy: 78.50\n",
      "Epoch 26 complete, train loss: 0.724, test loss: 0.606, accuracy: 80.20\n",
      "Epoch 27 complete, train loss: 0.681, test loss: 0.589, accuracy: 82.00\n",
      "Epoch 28 complete, train loss: 0.647, test loss: 0.553, accuracy: 82.00\n",
      "Epoch 29 complete, train loss: 0.624, test loss: 0.548, accuracy: 83.70\n",
      "Epoch 30 complete, train loss: 0.609, test loss: 0.525, accuracy: 82.80\n",
      "Epoch 31 complete, train loss: 0.582, test loss: 0.516, accuracy: 85.10\n",
      "Epoch 32 complete, train loss: 0.563, test loss: 0.506, accuracy: 83.30\n",
      "Epoch 33 complete, train loss: 0.553, test loss: 0.490, accuracy: 85.50\n",
      "Epoch 34 complete, train loss: 0.533, test loss: 0.474, accuracy: 84.60\n",
      "Epoch 35 complete, train loss: 0.516, test loss: 0.462, accuracy: 86.60\n",
      "Epoch 36 complete, train loss: 0.506, test loss: 0.450, accuracy: 85.80\n",
      "Epoch 37 complete, train loss: 0.495, test loss: 0.447, accuracy: 87.00\n",
      "Epoch 38 complete, train loss: 0.482, test loss: 0.430, accuracy: 86.20\n",
      "Epoch 39 complete, train loss: 0.469, test loss: 0.430, accuracy: 87.50\n",
      "Epoch 40 complete, train loss: 0.464, test loss: 0.420, accuracy: 86.70\n",
      "Epoch 41 complete, train loss: 0.456, test loss: 0.417, accuracy: 88.10\n",
      "Epoch 42 complete, train loss: 0.450, test loss: 0.406, accuracy: 87.90\n",
      "Epoch 43 complete, train loss: 0.435, test loss: 0.403, accuracy: 88.30\n",
      "Epoch 44 complete, train loss: 0.433, test loss: 0.393, accuracy: 88.20\n",
      "Epoch 45 complete, train loss: 0.427, test loss: 0.391, accuracy: 89.00\n",
      "Epoch 46 complete, train loss: 0.420, test loss: 0.382, accuracy: 88.40\n",
      "Epoch 47 complete, train loss: 0.414, test loss: 0.381, accuracy: 89.00\n",
      "Epoch 48 complete, train loss: 0.404, test loss: 0.375, accuracy: 88.70\n",
      "Epoch 49 complete, train loss: 0.394, test loss: 0.372, accuracy: 89.20\n",
      "Epoch 50 complete, train loss: 0.393, test loss: 0.366, accuracy: 89.30\n",
      "Epoch 51 complete, train loss: 0.388, test loss: 0.365, accuracy: 89.00\n",
      "Epoch 52 complete, train loss: 0.383, test loss: 0.359, accuracy: 89.30\n",
      "Epoch 53 complete, train loss: 0.373, test loss: 0.361, accuracy: 89.30\n",
      "Epoch 54 complete, train loss: 0.373, test loss: 0.356, accuracy: 89.50\n",
      "Epoch 55 complete, train loss: 0.368, test loss: 0.359, accuracy: 89.50\n",
      "Epoch 56 complete, train loss: 0.370, test loss: 0.356, accuracy: 89.50\n",
      "Epoch 57 complete, train loss: 0.364, test loss: 0.357, accuracy: 89.30\n",
      "Epoch 58 complete, train loss: 0.360, test loss: 0.356, accuracy: 89.60\n",
      "Epoch 59 complete, train loss: 0.357, test loss: 0.356, accuracy: 89.10\n",
      "Epoch 60 complete, train loss: 0.354, test loss: 0.356, accuracy: 89.20\n",
      "Epoch 61 complete, train loss: 0.350, test loss: 0.354, accuracy: 89.50\n",
      "Epoch 62 complete, train loss: 0.352, test loss: 0.354, accuracy: 89.30\n",
      "Epoch 63 complete, train loss: 0.351, test loss: 0.350, accuracy: 89.70\n",
      "Epoch 64 complete, train loss: 0.347, test loss: 0.350, accuracy: 89.40\n",
      "Epoch 65 complete, train loss: 0.342, test loss: 0.345, accuracy: 89.40\n",
      "Epoch 66 complete, train loss: 0.342, test loss: 0.346, accuracy: 89.50\n",
      "Epoch 67 complete, train loss: 0.344, test loss: 0.339, accuracy: 90.20\n",
      "Epoch 68 complete, train loss: 0.334, test loss: 0.338, accuracy: 89.90\n",
      "Epoch 69 complete, train loss: 0.330, test loss: 0.329, accuracy: 90.10\n",
      "Epoch 70 complete, train loss: 0.324, test loss: 0.330, accuracy: 90.20\n",
      "Epoch 71 complete, train loss: 0.319, test loss: 0.323, accuracy: 90.10\n",
      "Epoch 72 complete, train loss: 0.318, test loss: 0.320, accuracy: 90.40\n",
      "Epoch 73 complete, train loss: 0.308, test loss: 0.314, accuracy: 90.10\n",
      "Epoch 74 complete, train loss: 0.307, test loss: 0.316, accuracy: 90.60\n",
      "Epoch 75 complete, train loss: 0.305, test loss: 0.308, accuracy: 90.40\n",
      "Epoch 76 complete, train loss: 0.305, test loss: 0.311, accuracy: 90.50\n",
      "Epoch 77 complete, train loss: 0.301, test loss: 0.305, accuracy: 90.40\n",
      "Epoch 78 complete, train loss: 0.296, test loss: 0.305, accuracy: 90.90\n",
      "Epoch 79 complete, train loss: 0.292, test loss: 0.300, accuracy: 90.40\n",
      "Epoch 80 complete, train loss: 0.288, test loss: 0.301, accuracy: 90.80\n",
      "Epoch 81 complete, train loss: 0.286, test loss: 0.298, accuracy: 90.90\n",
      "Epoch 82 complete, train loss: 0.286, test loss: 0.296, accuracy: 91.30\n",
      "Epoch 83 complete, train loss: 0.281, test loss: 0.294, accuracy: 91.10\n",
      "Epoch 84 complete, train loss: 0.278, test loss: 0.294, accuracy: 91.20\n",
      "Epoch 85 complete, train loss: 0.280, test loss: 0.290, accuracy: 91.50\n",
      "Epoch 86 complete, train loss: 0.274, test loss: 0.289, accuracy: 91.40\n",
      "Epoch 87 complete, train loss: 0.267, test loss: 0.288, accuracy: 91.10\n",
      "Epoch 88 complete, train loss: 0.267, test loss: 0.288, accuracy: 91.40\n",
      "Epoch 89 complete, train loss: 0.269, test loss: 0.286, accuracy: 91.30\n",
      "Epoch 90 complete, train loss: 0.270, test loss: 0.286, accuracy: 91.60\n",
      "Epoch 91 complete, train loss: 0.262, test loss: 0.282, accuracy: 91.50\n",
      "Epoch 92 complete, train loss: 0.261, test loss: 0.283, accuracy: 91.80\n",
      "Epoch 93 complete, train loss: 0.265, test loss: 0.282, accuracy: 91.60\n",
      "Epoch 94 complete, train loss: 0.263, test loss: 0.280, accuracy: 91.80\n",
      "Epoch 95 complete, train loss: 0.261, test loss: 0.277, accuracy: 91.80\n",
      "Epoch 96 complete, train loss: 0.261, test loss: 0.276, accuracy: 91.70\n",
      "Epoch 97 complete, train loss: 0.259, test loss: 0.275, accuracy: 91.60\n",
      "Epoch 98 complete, train loss: 0.258, test loss: 0.273, accuracy: 91.90\n",
      "Epoch 99 complete, train loss: 0.253, test loss: 0.273, accuracy: 92.00\n",
      "Epoch 100 complete, train loss: 0.251, test loss: 0.272, accuracy: 91.90\n",
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "losses = train(model, optimizer, train_dataloader, test_dataloader, epochs=100, device=device, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
