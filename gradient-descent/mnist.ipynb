{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1ac3d0-b01d-4597-ba97-004d58b85316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28583600-2e6f-4759-9e9f-c5b087ef2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_dataset(\"mnist\")\n",
    "train, test = mnist.get(\"train\"), mnist.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6693dc6e-5cce-49af-8072-89ddd7c983f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_format(type=\"numpy\", columns=[\"image\", \"label\"])\n",
    "test.set_format(type=\"numpy\", columns=[\"image\", \"label\"])\n",
    "num_train_samples = 10000\n",
    "num_test_samples = 1000\n",
    "\n",
    "train_indices = np.random.choice(num_train_samples, num_train_samples, replace=False)\n",
    "test_indices = np.random.choice(num_test_samples, num_test_samples, replace=False)\n",
    "train = train.rename_column(\"image\", \"input\").select(train_indices)\n",
    "test = test.rename_column(\"image\", \"input\").select(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe26ee2-d4aa-4a73-965f-7e61a2cdc8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be53577d8b54af6923cf8ad4e736557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ed33423b404cc6b7645758be382c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(example):\n",
    "    arr = np.reshape(example[\"input\"], -1)\n",
    "    arr = arr / np.linalg.norm(arr, axis=-1, keepdims=True)\n",
    "    example[\"input\"] = arr\n",
    "    return example\n",
    "\n",
    "train = train.map(preprocess, num_proc=2)\n",
    "test = test.map(preprocess, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dfbf84-963a-4231-acc6-b24ed0e5df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.from_numpy(train[\"input\"]).float().squeeze()\n",
    "test_inputs = torch.from_numpy(test[\"input\"]).float().squeeze()\n",
    "train_labels = torch.from_numpy(train[\"label\"]).long()\n",
    "test_labels = torch.from_numpy(test[\"label\"]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fd4ac4-b049-492c-884e-afc8064dd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_inputs, train_labels)\n",
    "test_dataset = data.TensorDataset(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4dd86ed-fb34-4c30-bc3f-8912dab76e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(28 * 28, 512)\n",
    "        self.norm_1 = nn.LayerNorm(512)\n",
    "        self.drop_1 = nn.Dropout(p=0.5)\n",
    "        self.linear_2 = nn.Linear(512, 512)\n",
    "        self.norm_2 = nn.LayerNorm(512)\n",
    "        self.drop_2 = nn.Dropout(p=0.25)\n",
    "        self.linear_3 = nn.Linear(512, 256)\n",
    "        self.norm_3 = nn.LayerNorm(256)\n",
    "        self.drop_3 = nn.Dropout(p=0.25)\n",
    "        self.linear_4 = nn.Linear(256, 256)\n",
    "        self.norm_4 = nn.LayerNorm(256)\n",
    "        self.linear_5 = nn.Linear(256, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_1(f.relu(self.norm_1(self.linear_1(x))))\n",
    "        x = self.drop_2(f.relu(self.norm_2(self.linear_2(x))))\n",
    "        x = self.drop_3(f.relu(self.norm_3(self.linear_3(x))))\n",
    "        x = f.relu(self.norm_4(self.linear_4(x)))\n",
    "        out = self.linear_5(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd2d913-8c03-4247-8aec-23d992e7d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size):\n",
    "    return data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)\n",
    "\n",
    "def test(model, dataloader,  device=None, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Testing has started\")\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "            \n",
    "        test_loss /= len(dataloader)\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"Testing complete, loss: {test_loss:.3f}\")\n",
    "        \n",
    "    return test_loss\n",
    "\n",
    "def train(model, optimizer, train_dataloader, test_dataloader, epochs=10, device=None, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Training has started\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        num_samples = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                correct = torch.sum(torch.argmax(outputs, dim=-1) == labels)\n",
    "                accuracy += correct.item()\n",
    "                num_samples += len(labels)\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        accuracy /= num_samples\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1} complete, train loss: {train_loss:.3f}, test loss: {test_loss:.3f}, accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training is complete\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dbdc3-2cf6-4187-8c0a-9dd809380f4e",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d552508-7ac6-41ea-9f33-0e51bb672f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dataloader = create_dataloader(train_dataset, batch_size=len(train_dataset))\n",
    "test_dataloader = create_dataloader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6826022-8e5c-4749-9b05-88a1c5df5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 867338\n"
     ]
    }
   ],
   "source": [
    "print(f\"parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce172db-fe01-4b15-90b0-5e8438931975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "Epoch 1 complete, train loss: 2.372, test loss: 2.210, accuracy: 24.30\n",
      "Epoch 2 complete, train loss: 2.302, test loss: 2.111, accuracy: 28.90\n",
      "Epoch 3 complete, train loss: 2.243, test loss: 1.954, accuracy: 45.00\n",
      "Epoch 4 complete, train loss: 2.183, test loss: 1.878, accuracy: 45.30\n",
      "Epoch 5 complete, train loss: 2.131, test loss: 1.797, accuracy: 40.60\n",
      "Epoch 6 complete, train loss: 2.085, test loss: 2.128, accuracy: 18.30\n",
      "Epoch 7 complete, train loss: 2.184, test loss: 1.969, accuracy: 29.00\n",
      "Epoch 8 complete, train loss: 2.150, test loss: 1.916, accuracy: 46.60\n",
      "Epoch 9 complete, train loss: 2.094, test loss: 2.151, accuracy: 29.60\n",
      "Epoch 10 complete, train loss: 2.120, test loss: 2.546, accuracy: 21.00\n",
      "Epoch 11 complete, train loss: 2.450, test loss: 1.967, accuracy: 34.30\n",
      "Epoch 12 complete, train loss: 2.124, test loss: 1.746, accuracy: 42.50\n",
      "Epoch 13 complete, train loss: 1.939, test loss: 1.648, accuracy: 40.20\n",
      "Epoch 14 complete, train loss: 1.881, test loss: 1.869, accuracy: 34.10\n",
      "Epoch 15 complete, train loss: 2.001, test loss: 2.074, accuracy: 32.70\n",
      "Epoch 16 complete, train loss: 2.175, test loss: 1.866, accuracy: 39.20\n",
      "Epoch 17 complete, train loss: 1.988, test loss: 2.285, accuracy: 24.30\n",
      "Epoch 18 complete, train loss: 2.248, test loss: 2.428, accuracy: 34.60\n",
      "Epoch 19 complete, train loss: 2.359, test loss: 1.787, accuracy: 46.80\n",
      "Epoch 20 complete, train loss: 1.934, test loss: 2.209, accuracy: 20.30\n",
      "Epoch 21 complete, train loss: 2.145, test loss: 2.684, accuracy: 28.50\n",
      "Epoch 22 complete, train loss: 2.589, test loss: 2.331, accuracy: 30.50\n",
      "Epoch 23 complete, train loss: 2.371, test loss: 1.467, accuracy: 54.70\n",
      "Epoch 24 complete, train loss: 1.718, test loss: 1.369, accuracy: 56.60\n",
      "Epoch 25 complete, train loss: 1.624, test loss: 1.266, accuracy: 56.80\n",
      "Epoch 26 complete, train loss: 1.522, test loss: 1.356, accuracy: 56.00\n",
      "Epoch 27 complete, train loss: 1.602, test loss: 1.170, accuracy: 62.20\n",
      "Epoch 28 complete, train loss: 1.425, test loss: 1.963, accuracy: 40.10\n",
      "Epoch 29 complete, train loss: 1.987, test loss: 1.694, accuracy: 39.50\n",
      "Epoch 30 complete, train loss: 1.744, test loss: 1.933, accuracy: 41.30\n",
      "Epoch 31 complete, train loss: 1.931, test loss: 2.651, accuracy: 17.50\n",
      "Epoch 32 complete, train loss: 2.476, test loss: 2.129, accuracy: 40.30\n",
      "Epoch 33 complete, train loss: 2.109, test loss: 1.623, accuracy: 49.20\n",
      "Epoch 34 complete, train loss: 1.793, test loss: 1.658, accuracy: 43.20\n",
      "Epoch 35 complete, train loss: 1.716, test loss: 1.101, accuracy: 63.90\n",
      "Epoch 36 complete, train loss: 1.345, test loss: 1.079, accuracy: 61.80\n",
      "Epoch 37 complete, train loss: 1.182, test loss: 1.020, accuracy: 64.80\n",
      "Epoch 38 complete, train loss: 1.186, test loss: 1.275, accuracy: 59.10\n",
      "Epoch 39 complete, train loss: 1.368, test loss: 1.210, accuracy: 53.90\n",
      "Epoch 40 complete, train loss: 1.266, test loss: 1.322, accuracy: 62.10\n",
      "Epoch 41 complete, train loss: 1.394, test loss: 1.433, accuracy: 55.30\n",
      "Epoch 42 complete, train loss: 1.386, test loss: 1.494, accuracy: 56.50\n",
      "Epoch 43 complete, train loss: 1.539, test loss: 1.772, accuracy: 47.70\n",
      "Epoch 44 complete, train loss: 1.835, test loss: 1.123, accuracy: 61.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/__init__.py\", line 1854, in <module>\n",
      "    from . import _meta_registrations\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 6242, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/__init__.py\", line 1854, in <module>\n",
      "    activate_meta()\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 6239, in activate_meta\n",
      "    from . import _meta_registrations\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 6242, in <module>\n",
      "    _meta_lib_dont_use_me_use_register_meta.impl(op_overload, fn)\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/library.py\", line 168, in impl\n",
      "    self.m.impl(name, dispatch_key if dispatch_key != \"\" else \"CompositeImplicitAutograd\", fn)\n",
      "KeyboardInterrupt\n",
      "    activate_meta()\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 6239, in activate_meta\n",
      "    _meta_lib_dont_use_me_use_register_meta.impl(op_overload, fn)\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/library.py\", line 168, in impl\n",
      "    self.m.impl(name, dispatch_key if dispatch_key != \"\" else \"CompositeImplicitAutograd\", fn)\n",
      "  File \"<frozen importlib._bootstrap>\", line 477, in _lock_unlock_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 372, in release\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b6/9bc2z2316vx9_v730fprmrnr0000gn/T/ipykernel_85201/3952519297.py\", line 1, in <module>\n",
      "    losses = train(model, optimizer, train_dataloader, test_dataloader, epochs=100, device=device, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/b6/9bc2z2316vx9_v730fprmrnr0000gn/T/ipykernel_85201/2650912727.py\", line 36, in train\n",
      "    for inputs, labels in train_dataloader:\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1150, in get_records\n",
      "    mod = inspect.getmodule(cf.tb_frame)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 1006, in getmodule\n",
      "    f = getabsfile(module)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 976, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen posixpath>\", line 425, in abspath\n",
      "  File \"<frozen posixpath>\", line 413, in normpath\n",
      "  File \"/Users/tonimo/git/teaching-networks/venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 85452) is killed by signal: Interrupt: 2. \n"
     ]
    }
   ],
   "source": [
    "losses = train(model, optimizer, train_dataloader, test_dataloader, epochs=100, device=device, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
